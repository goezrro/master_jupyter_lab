{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d19047c-e28c-4d66-8e4b-f0c3b2379bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EJERCICIO 1\n",
    "# cargar librerias-----------------------------------------------\n",
    "import pandas as pd\n",
    "import os\n",
    "import tarfile\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "from pandas.core.common import flatten\n",
    "from plotnine import *\n",
    "from array import *\n",
    "import scipy.stats as stats\n",
    "import math\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.stats.api as sms\n",
    "from tabulate import tabulate\n",
    "# definir las rutas y caminos donde se encuentran los datos------\n",
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/\"\n",
    "# path que se va a crear en nuestro sistema----------------------\n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "# lugar de descarga del dataset----------------------------------\n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
    "\n",
    "# definir una funcion que obtenga los datos y los descargue-----\n",
    "def fetch_housing_data(housing_url=HOUSING_URL, \n",
    "housing_path=HOUSING_PATH):\n",
    "    if not os.path.isdir(housing_path):\n",
    "        os.makedirs(housing_path)\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()\n",
    "#fetch_housing_data()\n",
    "# definir una funcion que cargue el csv en un dataframe----------\n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)\n",
    "housing = load_housing_data()\n",
    "housing['oceano'] = [1 if x == '<1H OCEAN' else \n",
    "                     1 if x == 'NEAR OCEAN' else \n",
    "                     0 for x in housing['ocean_proximity']] \n",
    "# comprobacion de la variable oceano-----------------------------\n",
    "print(housing.info())\n",
    "print(housing[\"ocean_proximity\"].value_counts())\n",
    "print(housing[\"oceano\"].value_counts())\n",
    "# importar clase-------------------------------------------------\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# importar estandarizador-.--------------------------------------\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#definir variable respuesta\n",
    "x = housing[\"median_house_value\"].values.reshape(-1,1)\n",
    "# estandarizamos x-----------------------------------------------\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x)\n",
    "x_prepared = scaler.transform(x)\n",
    "# separar variable respuesta del dataset-------------------------\n",
    "y = housing[\"oceano\"].values.reshape(-1,1).ravel()\n",
    "# ajustar el modelo----------------------------------------------\n",
    "logistic_reg = LogisticRegression()\n",
    "logistic_reg.fit(x_prepared, y)\n",
    "# obtener coeficientes del modelo--------------------------------\n",
    "# intercepto\n",
    "print(\"El intercepto es = %.3f\" % logistic_reg.intercept_)\n",
    "# coeficientes de regresion\n",
    "print(\"El coeficiente es = %.3f\" % logistic_reg.coef_)\n",
    "# predecir clase-------------------------------------------------\n",
    "x_nueva = [[250000]]\n",
    "# estandarizamos la observacion\n",
    "x_nueva_prepared = scaler.transform(x_nueva)\n",
    "# predecir nueva casa--------------------------------------------\n",
    "clase_predicha = logistic_reg.predict(x_nueva_prepared)\n",
    "print(clase_predicha)\n",
    "# calcular probabilidad------------------------------------------\n",
    "clase_predicha_prob =logistic_reg.predict_proba(x_nueva_prepared)\n",
    "# sacar por pantalla las probabilidades de 0 y de 1--------------\n",
    "print(\"Pr(oceano = 0|median_housing_value = 250000) = %.4f\" % clase_predicha_prob[0,0],\",\", \n",
    "\"\\nPr(oceano = 1|median_housing_value = 250000) = %.4f\" % clase_predicha_prob[0,1],\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3257ed7c-e482-4ffd-9f1b-e292a0b2b240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO 2\n",
    "# CONSTRUIR MATRIZ X---------------------------------------------\n",
    "# quitar variable ocean_proximity--------------------------------\n",
    "housing_num = housing.drop(\"ocean_proximity\", axis=1)\n",
    "housing_num = housing_num.drop(\"oceano\", axis=1)\n",
    "housing_num = housing_num.drop(\"longitude\", axis=1)\n",
    "housing_num = housing_num.drop(\"latitude\", axis=1)\n",
    "# importar el \"imputador\"----------------------------------------\n",
    "from sklearn.impute import SimpleImputer\n",
    "# importar el \"estandarizador\"-----------------------------------\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# importar la clase pipeline\"------------------------------------\n",
    "from sklearn.pipeline import Pipeline\n",
    "# definir el pipeline--------------------------------------------\n",
    "num_pipeline = Pipeline([\n",
    "        (\"imputador\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"std_scaler\", StandardScaler()),\n",
    "    ])\n",
    "# aplicar el pipeline--------------------------------------------\n",
    "housing_num_tr = num_pipeline.fit_transform(housing_num)\n",
    "# importar clases------------------------------------------------\n",
    "from sklearn.compose import ColumnTransformer\n",
    "# atributos de las variables numericas---------------------------\n",
    "num_attribs = list(housing_num)\n",
    "# definir full pipeline------------------------------------------\n",
    "full_pipeline = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, num_attribs)\n",
    "    ])\n",
    "housing_prepared = full_pipeline.fit_transform(housing_num)\n",
    "\n",
    "# definir matriz X\n",
    "X = housing_prepared\n",
    "# separar variable respuesta del dataset-------------------------\n",
    "y = housing[\"oceano\"].values.reshape(-1,1).ravel()\n",
    "# ajustar el modelo----------------------------------------------\n",
    "logistic_reg_m = LogisticRegression()\n",
    "logistic_reg_m.fit(X, y)\n",
    "# obtener coeficientes del modelo--------------------------------\n",
    "# intercepto\n",
    "print(\"El intercepto es\", logistic_reg_m.intercept_)\n",
    "# coeficientes de regresion\n",
    "# print(\"Los coeficientes de las variables:\", \n",
    "# list(housing_num.columns.values.tolist()) ,  \"son:\", \n",
    "# logistic_reg_m.coef_)\n",
    "# podemos poner en una tabla estos valores-----------------------\n",
    "# poner nombres de las variables en una lista--------------------\n",
    "variables = housing_num.columns.values.tolist()\n",
    "# poner los coeficientes en otra lista---------------------------\n",
    "coefs = logistic_reg_m.coef_.tolist()[0]\n",
    "# definir las filas de la tabla----------------------------------\n",
    "table = zip(variables, coefs)\n",
    "# imprimir las tablas con nombres de las columnas (headers)------\n",
    "print(tabulate(table, headers = [\"Variable\", \"Coeficiente\"]))\n",
    "# obtener observacion--------------------------------------------\n",
    "housing_new = pd.DataFrame(np.array([[35, 2000, 1000, 1200, 900,\n",
    "10, 250000]]), columns = variables)\n",
    "# estandarizar---------------------------------------------------\n",
    "scaler2 = StandardScaler()\n",
    "scaler2.fit(housing_num)\n",
    "housing_new_prepared = scaler2.transform(housing_new)\n",
    "# valor estandarizado--------------------------------------------\n",
    "print(housing_new_prepared)\n",
    "# predecir clase------------------------------------------\n",
    "clase_predicha=logistic_reg_m.predict(housing_new_prepared)\n",
    "print(clase_predicha)\n",
    "# calcular probabilidad------------------------------------------\n",
    "clase_predicha_prob=logistic_reg_m.predict_proba(housing_new_prepared)\n",
    "# sacar por pantalla las probabilidades de 0 y de 1--------------\n",
    "print(\"Pr(oceano = 0|housing_new) = %.4f\" % clase_predicha_prob[0,0],\n",
    "\",\",\"\\nPr(oceano = 1|housing_new) = %.4f\" % clase_predicha_prob[0,1],\n",
    "\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103e9bd0-e4be-4edf-b6bb-321a9e074e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EJERCICIO 3\n",
    "#seleccionar predictores-----------------------------------------\n",
    "predictores = housing_num[[\"median_house_value\",\n",
    "\"total_rooms\"]]\n",
    "# pegar la clase a la base con los predictores estandarizados----\n",
    "puntos = predictores.copy()\n",
    "puntos[\"oceano\"] = housing[[\"oceano\"]]\n",
    "puntos[\"oceano\"] = puntos[\"oceano\"].astype(object)\n",
    "\n",
    "puntos.head()\n",
    "puntos.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1c9249-edbf-4690-89f2-f92d2f86817b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pintar la clase------------------------------------------------\n",
    "(\n",
    "    ggplot(puntos, aes(x = \"median_house_value\", \n",
    "    y = \"total_rooms\", fill = \"oceano\")) +\n",
    "    geom_point() +\n",
    "    ylab(\"X2\") +\n",
    "    xlab(\"X1\") +\n",
    "    theme_bw() +\n",
    "    theme(legend_position = \"right\",\n",
    "subplots_adjust={'right': 0.8})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cff7e3c-274e-4290-ae40-c09da6d244ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estandarizar predictores---------------------------------------\n",
    "scaler3 = StandardScaler()\n",
    "scaler3.fit(predictores)\n",
    "predictores_prepared = scaler3.transform(predictores)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# crear modelo con K = 10----------------------------------------\n",
    "model_KNN_10 = KNeighborsClassifier(n_neighbors = 10)\n",
    "# utilizamos un modelo donde usamos todos los puntos-------------\n",
    "model_KNN_10.fit(predictores_prepared, y)\n",
    "# definimos una rejilla de puntos\n",
    "# valores de x1\n",
    "min_x1 = min(predictores_prepared[:,0])\n",
    "max_x1 = max(predictores_prepared[:,0])\n",
    "x1_values = np.linspace(min_x1, max_x1, 101)\n",
    "# valores de x2\n",
    "min_x2 = min(predictores_prepared[:,1])\n",
    "max_x2 = max(predictores_prepared[:,1])\n",
    "x2_values = np.linspace(min_x2, max_x2, 101)\n",
    "\n",
    "x1_grid, x2_grid =  np.meshgrid(x1_values, x2_values)  \n",
    "x1_grid = x1_grid.flatten()\n",
    "x2_grid = x2_grid.flatten() \n",
    "x_grid = pd.DataFrame({'x1':x1_grid, 'x2':x2_grid})\n",
    "\n",
    "# tipos----------------------------------------------------------\n",
    "pred_10 = model_KNN_10.predict(x_grid)\n",
    "\n",
    "regiones_10 = x_grid.copy()\n",
    "# pegar los tipos predichos a la rejilla-------------------------\n",
    "regiones_10[\"clase\"] = pred_10\n",
    "regiones_10[\"clase\"] = regiones_10[\"clase\"].astype(object)\n",
    "# ver cuantos hay de cada en la rejilla\n",
    "print(regiones_10[\"clase\"].value_counts())\n",
    "\n",
    "# pintar la rejilla----------------------------------------------\n",
    "(\n",
    "    ggplot(regiones_10, aes(\n",
    "    x = \"x1\", \n",
    "    y = \"x2\",\n",
    "    fill = \"clase\")) +\n",
    "    geom_point(size = 1) +\n",
    "    ylab(\"X2\") +\n",
    "    xlab(\"X1\") +\n",
    "    theme_bw() +\n",
    "    theme(legend_position = \"right\",\n",
    "subplots_adjust={'right': 0.8})\n",
    ")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# crear modelo con K = 10----------------------------------------\n",
    "model_KNN_1 = KNeighborsClassifier(n_neighbors = 1)\n",
    "# utilizamos un modelo donde usamos todos los puntos-------------\n",
    "model_KNN_1.fit(predictores_prepared, y)\n",
    "\n",
    "# tipos----------------------------------------------------------\n",
    "pred_1 = model_KNN_1.predict(x_grid)\n",
    "\n",
    "regiones_1 = x_grid.copy()\n",
    "# pegar los tipos predichos a la rejilla-------------------------\n",
    "regiones_1[\"clase\"] = pred_1\n",
    "regiones_1[\"clase\"] = regiones_1[\"clase\"].astype(object)\n",
    "print(regiones_1[\"clase\"].value_counts())\n",
    "\n",
    "# pintar la rejilla----------------------------------------------\n",
    "(\n",
    "    ggplot(regiones_1, aes(\n",
    "    x = \"x1\", \n",
    "    y = \"x2\",\n",
    "    fill = \"clase\")) +\n",
    "    geom_point(size = 1) +\n",
    "    ylab(\"X2\") +\n",
    "    xlab(\"X1\") +\n",
    "    theme_bw() +\n",
    "    theme(legend_position = \"right\",\n",
    "subplots_adjust={'right': 0.8})\n",
    ")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# crear modelo con K = 10----------------------------------------\n",
    "model_KNN_100 = KNeighborsClassifier(n_neighbors = 100)\n",
    "# utilizamos un modelo donde usamos todos los puntos-------------\n",
    "model_KNN_100.fit(predictores_prepared, y)\n",
    "\n",
    "# tipos----------------------------------------------------------\n",
    "pred_100 = model_KNN_100.predict(x_grid)\n",
    "\n",
    "regiones_100 = x_grid.copy()\n",
    "# pegar los tipos predichos a la rejilla-------------------------\n",
    "regiones_100[\"clase\"] = pred_100\n",
    "regiones_100[\"clase\"] = regiones_100[\"clase\"].astype(object)\n",
    "print(regiones_100[\"clase\"].value_counts())\n",
    "\n",
    "# pintar la rejilla----------------------------------------------\n",
    "(\n",
    "    ggplot(regiones_100, aes(\n",
    "    x = \"x1\", \n",
    "    y = \"x2\",\n",
    "    fill = \"clase\")) +\n",
    "    geom_point(size = 1) +\n",
    "    ylab(\"X2\") +\n",
    "    xlab(\"X1\") +\n",
    "    theme_bw() +\n",
    "    theme(legend_position = \"right\",\n",
    "subplots_adjust={'right': 0.8})\n",
    ")\n",
    "# Encontrar el valor optimo de K\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# valores de K que vamos a probar--------------------------------\n",
    "k_range = range(1, 100)\n",
    "# inicializar vector de puntuaciones-----------------------------\n",
    "k_scores = []\n",
    "# bucle\n",
    "for k in k_range:\n",
    "    # ajustar el modelo con k vecinos\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    # obtener puntuaciones de VC\n",
    "    scores = cross_val_score(knn, predictores_prepared, y, \n",
    "    cv = 10, scoring = \"accuracy\")\n",
    "    # Guardar puntuaciones en el vector\n",
    "    k_scores.append(scores.mean())\n",
    "# print(k_scores)\n",
    "# pintar valores-------------------------------------------------\n",
    "plt.plot(k_range, k_scores)\n",
    "plt.xlabel('Valor de K para KNN')\n",
    "plt.ylabel('Accuracy de VC')\n",
    "plt.show()\n",
    "\n",
    "print(\"El valor de K que maximiza la accuracy es\", \n",
    "np.argmax(k_scores) + 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
